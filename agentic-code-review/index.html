
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Patterns for delivering software with AI agents">
      
      
        <meta name="author" content="Bryan Finster">
      
      
        <link rel="canonical" href="https://bdfinst.github.io/ai-patterns/agentic-code-review/">
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../ai-development-playbook/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.4.14">
    
    
      
        <title>Agentic Code Review Guide - AI Patterns</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.fad675c6.min.css?v=20260212131249">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.356b1318.min.css?v=20260212131249">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/timestamps.css?v=20260212131249">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  
  <!-- Aggressive cache busting -->
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="Pragma" content="no-cache">
  <meta http-equiv="Expires" content="0">

  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#automated-code-review-with-ai-agents-reference-architecture" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="AI Patterns" class="md-header__button md-logo" aria-label="AI Patterns" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            AI Patterns
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Agentic Code Review Guide
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_1">
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



  

<nav class="md-nav md-nav--primary md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="AI Patterns" class="md-nav__button md-logo" aria-label="AI Patterns" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    AI Patterns
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Guides
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Agentic Code Review Guide
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Agentic Code Review Guide
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#the-problem-with-traditional-code-review" class="md-nav__link">
    <span class="md-ellipsis">
      The Problem with Traditional Code Review
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goal-automate-everything-automatable" class="md-nav__link">
    <span class="md-ellipsis">
      Goal: Automate Everything Automatable
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#a-two-phase-review-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      A Two-Phase Review Architecture
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#phase-1-deterministic-checks" class="md-nav__link">
    <span class="md-ellipsis">
      Phase 1: Deterministic Checks
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#phase-2-context-aware-agent-review" class="md-nav__link">
    <span class="md-ellipsis">
      Phase 2: Context-Aware Agent Review
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Phase 2: Context-Aware Agent Review">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#domain-alignment-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Domain Alignment Agent
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#test-quality-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Test Quality Agent
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#architecture-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Architecture Agent
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#documentation-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Documentation Agent
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naming-coherence-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Naming Coherence Agent
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#the-self-correction-loop" class="md-nav__link">
    <span class="md-ellipsis">
      The Self-Correction Loop
    </span>
  </a>
  
    <nav class="md-nav" aria-label="The Self-Correction Loop">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#auto-correctable-with-high-confidence" class="md-nav__link">
    <span class="md-ellipsis">
      Auto-Correctable with High Confidence
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auto-correctable-with-medium-confidence" class="md-nav__link">
    <span class="md-ellipsis">
      Auto-Correctable with Medium Confidence
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#not-auto-correctable" class="md-nav__link">
    <span class="md-ellipsis">
      Not Auto-Correctable
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#review-annotations" class="md-nav__link">
    <span class="md-ellipsis">
      Review Annotations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#override-mechanism" class="md-nav__link">
    <span class="md-ellipsis">
      Override Mechanism
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#agent-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Agent Configuration
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Agent Configuration">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#prompting-for-initial-configuration" class="md-nav__link">
    <span class="md-ellipsis">
      Prompting for Initial Configuration
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#example-test-quality-agent" class="md-nav__link">
    <span class="md-ellipsis">
      Example: Test Quality Agent
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trigger-points" class="md-nav__link">
    <span class="md-ellipsis">
      Trigger Points
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Trigger Points">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#on-demand" class="md-nav__link">
    <span class="md-ellipsis">
      On Demand
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on-push" class="md-nav__link">
    <span class="md-ellipsis">
      On Push
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#on-pull-request" class="md-nav__link">
    <span class="md-ellipsis">
      On Pull Request
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#continuous-background" class="md-nav__link">
    <span class="md-ellipsis">
      Continuous Background
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#ci-integration" class="md-nav__link">
    <span class="md-ellipsis">
      CI Integration
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#measuring-effectiveness" class="md-nav__link">
    <span class="md-ellipsis">
      Measuring Effectiveness
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#limitations-and-honest-tradeoffs" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations and Honest Tradeoffs
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#getting-started" class="md-nav__link">
    <span class="md-ellipsis">
      Getting Started
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ai-development-playbook/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI Development Playbook
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cd-defect-detection-and-remediation-cheat-sheet.md" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CD Defect Detection and Remediation Cheat Sheet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Articles
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Articles
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://bryanfinster.substack.com/p/ai-is-a-high-pass-filter-for-software" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI is a High Pass Filter for Software Delivery
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="https://bryanfinster.substack.com/p/incorporating-ai-without-crashing" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Incorporating AI Without Crashing
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="automated-code-review-with-ai-agents-reference-architecture">Automated Code Review with AI Agents Reference Architecture</h1>
<p><small>v1.0</small></p>
<p>A hybrid approach combining deterministic rules-based tooling with context-aware AI agents to automate everything that
can be automated about code review.</p>
<blockquote>
<p>It should be noted that this solution is for teams and organizations that are already have
a <a href="https://bryanfinster.substack.com/p/ai-is-a-high-pass-filter-for-software">solid continuous delivery process</a>.
For teams still on that journey, do not start here! Start with a vision of here.
Please read my article on how to <a href="https://bryanfinster.substack.com/p/incorporating-ai-without-crashing">get there faster with the assistance of agents</a>.</p>
</blockquote>
<h2 id="the-problem-with-traditional-code-review">The Problem with Traditional Code Review</h2>
<p>Rules-based tools should already handle mechanical concerns. Formatting, linting, static analysis, security scanning;these have deterministic right answers and shouldn't consume human attention. If your team is still catching formatting issues in review, fix your tooling.</p>
<p>Similarly, business logic correctness should be validated by tests, not by reading code. If a reviewer has to trace through implementation to determine whether it handles edge cases correctly, that's a missing test, not a review task.</p>
<p>This becomes automatable when business rules are documented as test scenarios before coding begins. Agents can then verify that tests exist for each documented scenario and that the tests actually assert the expected outcomes. Review shifts from implementation to requirements. Errors that slip through are requirement errors;scenarios that were never documented;not implementation bugs that a test review would have caught.</p>
<p>Even with proper tooling and test coverage, significant review time remains. Reviewers still evaluate naming coherence, domain alignment, architectural fit, documentation accuracy, and test quality;things that require understanding context and intent, not just pattern matching.</p>
<p>This was manageable when code generation was the bottleneck. A developer might produce a few hundred lines of reviewable code per day. Review capacity roughly matched generation capacity.</p>
<p>AI-assisted code generation has broken this balance. Developers using AI tools can generate code faster than teams can
review it. Pull requests queue up. Reviewers batch work to stay efficient, which increases cycle time. The feedback loop
that makes code review valuable, the fast iteration on design and approach, degrades.</p>
<p>The result is a choice between thoroughness and speed. Teams either maintain review quality and accept slower delivery, or they reduce review depth to keep up. Neither option is good.</p>
<p>The solution is to automate everything about code review that can be automated, reserving human attention for decisions
that genuinely require human judgment.</p>
<h2 id="goal-automate-everything-automatable">Goal: Automate Everything Automatable</h2>
<p>The goal is to reduce human review to only those decisions that genuinely require human judgment; design tradeoffs,
architectural direction, business logic validation. However, if you are doing any of these in code review, you need to
stop here and fix reasons these are not resolved before coding. Everything else should be caught and, where possible,
corrected automatically.</p>
<p>This process can run at any point: on commit, on push, on pull request creation, on demand, or continuously in the
background. The trigger doesn't matter. What matters is that by the time a human reviewer sees the code, the automatable
concerns have already been handled. Be aware that I am accountable to my AI spend rate and act accordingly when I do
this and will run this when I integrate to the trunk.</p>
<h2 id="a-two-phase-review-architecture">A Two-Phase Review Architecture</h2>
<p>This process separates concerns into what machines do well deterministically (Phase 1) and what requires contextual reasoning (Phase 2), with a feedback loop that allows automated correction before human review.</p>
<pre class="mermaid"><code>flowchart TD
    subgraph Review["Automated Review Process"]
        A[Review Triggered] --&gt; B{Phase 1: Deterministic Checks}

        subgraph Phase1["Phase 1: Rules-Based Tools"]
            B --&gt; C[Formatting &amp; Linting]
            B --&gt; D[Static Analysis]
            B --&gt; E[Security Scanning]
            B --&gt; F[Test Execution]
        end

        C --&gt; G{All Passed?}
        D --&gt; G
        E --&gt; G
        F --&gt; G

        G --&gt;|No| H[Auto-fix where possible]
        H --&gt; I{Fixable?}
        I --&gt;|Yes| B
        I --&gt;|No| J[Block with guidance]

        G --&gt;|Yes| K{Phase 2: Agent Review}

        subgraph Phase2["Phase 2: Context-Aware Agents"]
            K --&gt; L[Domain Alignment Agent]
            K --&gt; M[Test Quality Agent]
            K --&gt; N[Architecture Agent]
            K --&gt; O[Documentation Agent]
            K --&gt; P[Naming Coherence Agent]
        end

        L --&gt; Q[Aggregate Findings]
        M --&gt; Q
        N --&gt; Q
        O --&gt; Q
        P --&gt; Q

        Q --&gt; R{Critical Issues?}
        R --&gt;|Yes| S{Auto-correctable?}
        S --&gt;|Yes| T[Apply Agent Corrections]
        T --&gt; U{Re-review?}
        U --&gt;|Yes| K
        U --&gt;|No, max iterations| V[Present findings for decision]
        S --&gt;|No| V

        R --&gt;|No| W{Warnings?}
        W --&gt;|Yes| X[Attach warnings to review]
        W --&gt;|No| Y[Review Complete]
        X --&gt; Y

        V --&gt; Z{Override?}
        Z --&gt;|Yes, with justification| X
        Z --&gt;|No| AA[Address issues]
        AA --&gt; A
    end

    Y --&gt; AB[Ready for Human Review]
    AB --&gt; AC{Human Review}
    AC --&gt;|Approved| AD[Merge]
    AC --&gt;|Changes Requested| A</code></pre>
<h2 id="phase-1-deterministic-checks">Phase 1: Deterministic Checks</h2>
<p>These run first because they're fast, cheap, and have no false positives when configured correctly. No point wasting agent compute on code that won't compile.</p>
<ul>
<li>Formatting and Linting</li>
<li>Static Analysis</li>
<li>Security Scanning</li>
<li>CI Test Suite Execution</li>
</ul>
<h2 id="phase-2-context-aware-agent-review">Phase 2: Context-Aware Agent Review</h2>
<p>Once code passes mechanical checks, agents evaluate aspects that require understanding intent and context. Each agent operates as a specialist with a focused mandate.</p>
<h3 id="domain-alignment-agent">Domain Alignment Agent</h3>
<p>Reviews code against the domain model and ubiquitous language.</p>
<p><strong>Example:</strong></p>
<ul>
<li>Do new names align with established domain terminology?</li>
<li>Are abstractions at the right level for this bounded context?</li>
<li>Does this change respect aggregate boundaries?</li>
<li>Would a domain expert recognize these concepts?</li>
</ul>
<h3 id="test-quality-agent">Test Quality Agent</h3>
<p>Evaluates whether tests specify behavior or merely execute code.</p>
<p><strong>Example:</strong></p>
<ul>
<li>Do test names describe behavior from a user/caller perspective?</li>
<li>Are tests coupled to implementation details that will cause brittle failures?</li>
<li>Do assertions verify outcomes or just absence of exceptions?</li>
<li>Are edge cases from requirements covered?</li>
<li>Would these tests catch a regression, or just confirm the code runs?</li>
</ul>
<h3 id="architecture-agent">Architecture Agent</h3>
<p>Evaluates whether changes align with intended system structure.</p>
<p><strong>Example:</strong></p>
<ul>
<li>Does this change introduce dependencies that violate layer boundaries?</li>
<li>Is this the right module for this responsibility?</li>
<li>Does this move toward or away from documented architectural intent?</li>
<li>Are new patterns consistent with established patterns for similar problems?</li>
</ul>
<h3 id="documentation-agent">Documentation Agent</h3>
<p>Checks alignment between code and its documentation.</p>
<p><strong>Example:</strong></p>
<ul>
<li>Do README files still accurately describe the module after this change?</li>
<li>Are inline comments now stale or misleading?</li>
<li>Does API documentation reflect current behavior?</li>
<li>Should this change trigger an ADR update or new ADR?</li>
</ul>
<h3 id="naming-coherence-agent">Naming Coherence Agent</h3>
<p>Ensures terminology consistency across the codebase.</p>
<p><strong>Example:</strong></p>
<ul>
<li>Are similar concepts named consistently?</li>
<li>Do abbreviations match established patterns?</li>
<li>Are boolean names predictable?</li>
<li>Do method names follow codebase conventions?</li>
</ul>
<h2 id="the-self-correction-loop">The Self-Correction Loop</h2>
<p>Agent findings fall into three categories:</p>
<h3 id="auto-correctable-with-high-confidence">Auto-Correctable with High Confidence</h3>
<p>The agent can fix the issue and is confident the fix is correct. Examples: renaming to match conventions, updating stale comments with clear replacements, fixing terminology inconsistencies.</p>
<p>These corrections are applied automatically and the agent phase re-runs to verify the fix didn't introduce new issues. A maximum iteration limit (typically 2-3) prevents infinite loops.</p>
<h3 id="auto-correctable-with-medium-confidence">Auto-Correctable with Medium Confidence</h3>
<p>The agent can propose a fix but isn't certain it's correct. These are presented as suggested diffs that can be accepted, modified, or rejected.</p>
<h3 id="not-auto-correctable">Not Auto-Correctable</h3>
<p>Issues requiring human judgment: architectural decisions, test design, complex refactoring. These block the automated review with clear guidance on what needs attention.</p>
<h2 id="review-annotations">Review Annotations</h2>
<p>When warnings exist but don't block the review, they're attached as structured metadata. This creates a record of known rough edges, giving human reviewers context about what the automated process flagged and what was acknowledged.</p>
<h2 id="override-mechanism">Override Mechanism</h2>
<p>Non-critical agent findings can be overridden with justification. Overrides are logged and can be audited. Patterns of overrides for the same rule suggest the rule needs adjustment.</p>
<h2 id="agent-configuration">Agent Configuration</h2>
<p>Each agent requires configuration that establishes its review criteria and connects it to relevant context in your codebase.</p>
<h3 id="prompting-for-initial-configuration">Prompting for Initial Configuration</h3>
<p>When setting up an agent, provide it with:</p>
<ol>
<li><strong>Role and scope</strong> : What aspect of the code this agent owns and what it should ignore</li>
<li><strong>Reference material</strong> : Pointers to documentation, conventions, or examples that define "correct" for your codebase</li>
<li><strong>Output expectations</strong> : How findings should be categorized (severity, correctability) and what information to include</li>
<li><strong>Boundaries</strong> : What the agent should flag versus what it should leave to human judgment</li>
</ol>
<p>The agent should be able to learn your codebase's conventions from examples rather than exhaustive rules. Point it at good code and let it infer patterns.</p>
<h3 id="example-test-quality-agent">Example: Test Quality Agent</h3>
<div class="highlight"><pre><span></span><code>You are a test quality reviewer. Your job is to evaluate whether tests 
actually verify behavior or just execute code.

Reference the existing tests in /tests/unit/orders/ as examples of our 
preferred testing style. Note how test names describe outcomes, assertions 
check state changes, and mocks are minimal.

For each test file in the diff, evaluate:
- Does each test name describe a behavior outcome?
- Do assertions verify state changes, not just absence of errors?
- Are mocks used only for external boundaries, not internal collaborators?
- Would this test fail if the behavior regressed?

Categorize findings as:
- critical: Test provides false confidence (passes but doesn&#39;t verify behavior)
- warning: Test could be improved but does provide some verification
- suggestion: Stylistic improvement

For critical and warning findings, indicate whether you can propose a 
correction with high confidence, medium confidence, or if it requires 
human judgment.

Do not flag tests for external integrations or end-to-end tests; those 
follow different patterns and are outside your scope.
</code></pre></div>
<p>The prompt establishes scope (unit tests only), provides reference examples, defines the evaluation criteria, specifies output format, and sets boundaries. Adjust based on your codebase's testing philosophy.</p>
<h2 id="trigger-points">Trigger Points</h2>
<p>The review process can be invoked at multiple points depending on workflow needs:</p>
<h3 id="on-demand">On Demand</h3>
<p>Developer explicitly requests review of staged changes or a branch. Useful during development for early feedback before creating a pull request.</p>
<h3 id="on-push">On Push</h3>
<p>Review runs automatically when changes are pushed to a branch. Results are attached to the branch and visible before PR creation.</p>
<h3 id="on-pull-request">On Pull Request</h3>
<p>Review runs when a PR is created or updated. Findings are posted as PR comments, and auto-corrections can be committed directly to the branch.</p>
<h3 id="continuous-background">Continuous Background</h3>
<p>Review runs periodically on the main branch or long-lived feature branches, catching drift in documentation, architecture, or naming that accumulates over time even without direct changes.</p>
<h3 id="ci-integration">CI Integration</h3>
<p>CI pipeline triggers the full review process. CI results are authoritative; other trigger points provide early feedback but CI is the gate.</p>
<h2 id="measuring-effectiveness">Measuring Effectiveness</h2>
<p>Track these metrics to tune the process:</p>
<ul>
<li><strong>Override rate by agent</strong>: High override rates suggest miscalibrated rules</li>
<li><strong>Post-merge issues by category</strong>: Issues caught in production that agents should have flagged</li>
<li><strong>Agent false positive rate</strong>: Developer-reported findings that weren't actual issues</li>
<li><strong>Self-correction success rate</strong>: Percentage of auto-corrections that didn't require reversion</li>
</ul>
<p>Treat these like production defects and update the agents to prevent that class of issue.</p>
<h2 id="limitations-and-honest-tradeoffs">Limitations and Honest Tradeoffs</h2>
<p>This process adds latency. Phase 1 should complete in seconds; Phase 2 adds 10-60 seconds depending on configuration and
diff size. For rapid iteration, this might be run less frequently or with a subset of agents. However, consider this
compared to the manual alternative.</p>
<p>Agents hallucinate when information accuracy is low or the size of information exceeds the recommended threshhold. Good
practice is 50% the size of the context window. They will occasionally flag non-issues or suggest incorrect fixes when
this happens. The confidence scoring and human override
mechanisms exist because agent aren't responsible for the changes.</p>
<p>Context window limits mean agents see a slice of the codebase, not the whole thing. They may miss cross-cutting concerns
or historical context that isn't in their input window. A good practice is to have agents audit the code base and agent
configurations to suggest ways to make things better organized for their context windows.</p>
<p>This doesn't replace human review. It's aimed at focusing review only on things that cannot be revieed with
automation and that list is much shorter than it was.</p>
<h2 id="getting-started">Getting Started</h2>
<ol>
<li>Implement Phase 1 with standard tooling. I seriously hope that's already done</li>
<li>Add one agent, tuned to your codebase's patterns</li>
<li>Measure and adjust before adding more agents</li>
<li>Expand agent coverage based on where review feedback clusters</li>
</ol>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      2026-02-09
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.instant", "navigation.instant.prefetch", "navigation.tracking", "navigation.top", "toc.integrate", "search.suggest", "search.highlight"], "search": "../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.cd18aaf1.min.js?v=20260212131249"></script>
      
        <script src="../js/cache-bust.js?v=20260212131249"></script>
      
    
  </body>
</html>